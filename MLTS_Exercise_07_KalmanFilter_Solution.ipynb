{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLTS Exercise 06 - Kalman Filter</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to implement the Kalman filtering for a simple object tracking application.  Kalman filter (KF) is an optimal estimation problem where we have linear and Gaussian systems. These two properties are central to the KF, since they allow us to estimate the integrals and other computations analytically. \n",
    "\n",
    "The system includes prediction and observation models. In a tracking object problem, the prediction model can be defined by e.g. physical rules that give the relation between position of the object and its acceleration during time. Observations can be obtained by a type of a sensor, e.g. GPS, that can indicate the position of the object. It is easy to imagine that for a real-world application, we have to take into account noisy models. In KF, we model the noises for both models with Gaussian density (distribution). We are interested to combine these two models (sources of information), in order to optimally estimate the object position.\n",
    "\n",
    "KF is a probabilistic method. We have to estimate several probability densities such as predictive and filtering density. The good news is that, since we assumed the system is Gaussian and linear, all these densities become a Gaussian density. One can define a Gaussian density by estimating its first two moments namely mean and variance.  Hence, the computation of, e.g. filtering density at a certain point, boils down to the computation of its mean and variance.\n",
    "\n",
    "The KF algorithm is recursive. We compute the required densities (predictive and filtering density) once at a time for the whole trajectory of an object.\n",
    "\n",
    "This was a brief intuition behind the KF. For finding the exact explanation or formulation, please refer to your lecture slides or to the book of “Machine learning: a probabilistic perspective” by Kevin Murphy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task: Implement the prediction and filtering step of a kalman filter\n",
    "\n",
    "Important variables are explained with comments\n",
    "\n",
    "### Important formulas\n",
    "\n",
    "#### 1. Prediction\n",
    "\n",
    "* $\\bar z_t = F_t z_{t-1}  [+ B_t u_t ]$   -> **B_t and u_t are left out in this example!**\n",
    "* $\\bar \\Sigma_t = F_t \\Sigma_{t-1} F_t^T + R_t$\n",
    "\n",
    "#### 2. Filtering\n",
    "\n",
    "* $K_t = \\bar \\Sigma_t H_t^T (H_t \\bar \\Sigma_{t}H_t^T + Q_t)^{-1}$\n",
    "\n",
    "* $z_t = \\bar z_t + K_t (y_t - H_t \\bar z_t)$\n",
    "\n",
    "* $\\Sigma_t = (1 - K_t H_t) \\bar \\Sigma_t$\n",
    "\n",
    "#### Some hints\n",
    "\n",
    "* Initialize the priori prediction and priori covariance: $\\bar z_0$, $\\bar \\Sigma_0$ with the variables initMu and initCov\n",
    "\n",
    "* Start with the filtering step in the for loop after doing the initialization out of the for loop\n",
    "\n",
    "* You should end up with 5 lines of code in the for loop :-)\n",
    "\n",
    "* posterioriPred = $z_t$, posterioriErrorCov = $\\Sigma_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kalman_filter(observation: np.array, \n",
    "                  A: np.array,\n",
    "                  H: np.array,\n",
    "                  Q: np.array,\n",
    "                  R: np.array,\n",
    "                  initMu: np.array,\n",
    "                  initCov: np.array) -> tuple[np.array, np.arange]:\n",
    "    \"\"\"Kalman Filter Function\n",
    "\n",
    "    Args:\n",
    "        observation (np.array): observations\n",
    "        A (np.array): state relation matrix\n",
    "        H (np.array): state to observation relation matrix\n",
    "        Q (np.array): measurement noise covariance matrix\n",
    "        R (np.array): process noise covariance matrix\n",
    "        initMu (np.array): initial estimate of a posteriori expectation\n",
    "        initCov (np.array): initial estimate of a posteriori covariance matrix\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, np.arange]: Posterior prediction, posterior covariance\n",
    "    \"\"\"\n",
    "    numObservations = observation.shape[0]\n",
    "\n",
    "    # Initialize empty matrices for: priorPred, posteriorPred, priorErrorCov, posteriorErrorCov, kalmanGain\n",
    "    # Important: Use the correct shapes\n",
    "    dim = A.shape[0]\n",
    "\n",
    "    prioriPred = np.empty((numObservations + 1, dim))\n",
    "    posterioriPred = np.empty((numObservations, dim))\n",
    "    prioriErrorCov = np.empty((numObservations + 1, dim, dim))\n",
    "    posterioriErrorCov = np.empty((numObservations, dim, dim))\n",
    "    kalmanGain = np.empty((numObservations, dim, observation.shape[1]))\n",
    "\n",
    "    # Initialize prior prediction and prior covariance\n",
    "    prioriPred[0] = initMu\n",
    "    prioriErrorCov[0] = initCov\n",
    "    \n",
    "    for k in range(0, numObservations):\n",
    "        # compute predictive and filtering densities recursively for all observations\n",
    "        # which involves computation of mean and covariance for predictive and filtering denities\n",
    "        # Tipp: You can simplify matrix multiplications using the @ sign\n",
    "\n",
    "        # Measurement step (correction)\n",
    "        tmp = H @ prioriErrorCov[k] @ np.transpose(H) + Q\n",
    "        kalmanGain[k] = prioriErrorCov[k] @ np.transpose(H) @ np.linalg.pinv(tmp)\n",
    "        posterioriPred[k] = prioriPred[k] + kalmanGain[k] @ (observation[k] - H @ prioriPred[k])\n",
    "        posterioriErrorCov[k] = (np.eye(dim) - kalmanGain[k] @ H) @ prioriErrorCov[k]\n",
    "\n",
    "        # Time update (prediction)\n",
    "        prioriPred[k + 1] = A @ posterioriPred[k]\n",
    "        prioriErrorCov[k + 1] = A @ posterioriErrorCov[k] @ np.transpose(A) + R\n",
    "\n",
    "    return posterioriPred, prioriErrorCov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f474060e34b51be0081cd4b7f97c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Number of measurements over the distance: ', max=20, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(\n",
    "    numMeasurements=widgets.IntSlider(min=1, max=20, step=1, value=10, description='Number of measurements over the distance: '),\n",
    "    distanceStartEnd=widgets.IntSlider(min=20, max=200, step=1, value=100, description='Distance tracking object travels: '),\n",
    "    varObservations=widgets.Dropdown(options=[0.01, 0.001, 0.0001], value=0.001, description='Variance in x and y direction:'),\n",
    "    processNoiseScaling=widgets.Dropdown(options=[0.01, 0.001, 0.0001], value=0.001, description='Scaling for process noise model in filter:'),\n",
    "    observationNoiseScaling=widgets.Dropdown(options=[1., 0.1, 0.01], value=0.1, description='Scaling for observation noise model in filter:')\n",
    ")\n",
    "def plot(numMeasurements=10,\n",
    "         distanceStartEnd=100,\n",
    "         varObservations=0.001,\n",
    "         processNoiseScaling=0.001,\n",
    "         observationNoiseScaling=0.1):\n",
    "\n",
    "    # initial values of prior prediction and covariance\n",
    "    config = {'initMu': np.array([0, 10, 1, 0]),  # mean of first state; state at time 1\n",
    "              'initCov': np.eye(4) * 0.1,  # covariance of first state; state at time 1\n",
    "              'starting_point': 10\n",
    "             }\n",
    "    \n",
    "    # create observations\n",
    "    samplingPeriod = distanceStartEnd / numMeasurements\n",
    "    observation = np.empty((numMeasurements, 2))\n",
    "\n",
    "    for i in range(0, numMeasurements):\n",
    "        observation[i] = [0 + (i * samplingPeriod), config['starting_point']] \\\n",
    "                         + np.random.multivariate_normal([0, 0], [[varObservations, 0], [0, varObservations]], (1, 1))\n",
    "        \n",
    "    # definining transition, observation and noise matrices A, H, Q, R\n",
    "    A = np.eye(4)  # state relation matrix\n",
    "    A[0][2] = samplingPeriod\n",
    "    A[1][3] = samplingPeriod\n",
    "    H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]])  # state to observation relation matrix\n",
    "    R = processNoiseScaling * np.eye(4)  # process noise covariance matrix\n",
    "    Q = observationNoiseScaling * np.eye(2)  # measurement noise covariance matrix\n",
    "\n",
    "    # do kalman filtering step\n",
    "    mean, cov = kalman_filter(observation, A, H, Q, R, config['initMu'], config['initCov'])\n",
    "\n",
    "    # plot\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    ax = fig.gca()\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.ylim([9.9, 10.1])\n",
    "    plt.scatter(observation[:, 0], observation[:, 1], marker=\"x\", c=\"blue\", label=\"Observations\")\n",
    "    plt.plot(observation[:, 0], observation[:, 1], c=\"blue\")\n",
    "    plt.plot(mean[:, 0], mean[:, 1], c=\"red\")\n",
    "    plt.scatter(mean[:, 0], mean[:, 1], c=\"red\", label=\"Kalman\")\n",
    "    plt.plot(np.arange(0, distanceStartEnd), np.ones((distanceStartEnd)) * config['initMu'][1], c=\"black\", label=\"real\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ce972b8196c3bc344073d559e470958edd80946e92866da6533a1277d0d07bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
